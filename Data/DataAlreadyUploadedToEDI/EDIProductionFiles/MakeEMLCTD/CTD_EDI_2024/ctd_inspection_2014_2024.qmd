---
title: "CTD Visualization"
author: Abby Lewis, Katie Hoffman, and Adrienne Breef-Pilz
format:
  html:
    embed-resources: true
editor: visual
created: 23 April 2024
---

## Overview

This visualization script has two purposes:

1.  Creating a compiled data frame of ALL CTD data for EDI and inspecting the data before publishing

2.  Visualizing data currently staged on EDI

If you are a reviewer, you can skip some of the first sections focused on compiling data (see notes below)

## STEP 1: Load required packages

```{r load packages}
library(akima)
library(colorRamps)
library(plotly)
library(tidyverse)
library(lubridate)
library(plotly)
library(here)
source("../CTD_code/ctd_QAQC.R")

THIS_YEAR <- 2023 #Latest year of data
```

## STEP 2: Collate all CTD files and run QAQC

**Note: reviewers can skip this chunk**

This chunk will take a long time to run, because it involves QAQCing literally all historical CTD data

```{r Combine and qaqc all files}
# Combine all the CTD files and QAQC them. If you want to reprocess all the files then set force_reprocessing to T. 
ctd_folder <- here("Data", "DataNotYetUploadedToEDI", "Raw_CTD")
ctd_reprocessed <- ctd_QAQC(raw_downloads = here(ctd_folder, "RawDownloads"),
                            ctd_cast_csvs = here(ctd_folder, "csv_outputs"),
                            ctd_season_csvs = here(ctd_folder, "CTD_season_csvs"),
                            CTD_FOLDER = paste0(ctd_folder, "/"),
                            start_date = as.Date("2012-01-01"), #Since the beginning of the reservoir monitoring program
                            force_reprocessing = F, #Re-process all files
                            historical_files = T, # add in files before we save all casts
                            output_file_name = paste0("CTD_2013_", THIS_YEAR,".csv"),
                            intermediate_file_name = paste0("CTD_L0_2018_", THIS_YEAR,".csv"))

```

## STEP 3: Quick gut checks for reprocessing

```{r Check all files have been processed}
#Make sure all files have been processed
processed_files <- sub(".csv","",list.files("../csv_outputs"))
raw_files <- list.files("../RawDownloads")
raw_files <- sub(".cnv", "", raw_files[grepl(".cnv", raw_files)])
processed_files[!processed_files %in% raw_files]
raw_files[!raw_files %in% processed_files]
min(ctd_reprocessed$DateTime) # we've re-processed files since 2018 (but also added historical files above)
unique(ctd_reprocessed$Site)
unique(ctd_reprocessed$Reservoir)
```

## STEP 4: REVIEWERS- load data from EDI

REVIEWERS START HERE. Double check you have the right pasta link for the data package you are reviewing.

```{r read in EDI data}
# Read in Data from GitHub
ctd_edi <- read_csv("https://pasta-s.lternet.edu/package/data/eml/edi/1113/6/0432a298a90b2b662f26c46071f66b8a")
```

## STEP 5: Visualize data

```{r}
#Choose which data you want to visualize
#qaqc <- ctd_edi
qaqc <- ctd_reprocessed

# Basic checks
unique(qaqc$Site)
unique(qaqc$Reservoir)

#Function to plot all data for a given year as a heatmap
plot_var <- function(var_name, 
                     year, 
                     reservoirs = c("FCR", "BVR", "CCR"),
                     data = qaqc){
  
  var <- sym(var_name)
  flag <- sym(paste0("Flag_", var_name))
  qaqc_plotly <- data %>%
    filter(Reservoir %in% reservoirs, Site == 50, year(DateTime) %in% year) %>%
    sample_frac(.1) %>%
    ggplot(aes(x = DateTime, y = Depth_m, color = !!var, shape = as.factor(!!flag))) +
    scale_color_gradientn(colours = blue2green2red(100), na.value="gray") +
    scale_y_reverse() +
    geom_point() +
    ggtitle(year) +
    facet_grid(cols = vars(Reservoir), rows = vars(SN))
  ggplotly(qaqc_plotly)
  #print(qaqc_plotly)
}


vars_to_plot <- c("Temp_C", "DO_mgL", "DOsat_percent", "Cond_uScm", "Turbidity_NTU", "SpCond_uScm", "Chla_ugL", "pH", "PAR_umolm2s", "CDOM_ugL", "Phycoerythrin_ugL", "Phycocyanin_ugL", "DescRate_ms")
qaqc %>%
  filter(as.Date(DateTime) == as.Date("2021-07-28"))

qaqc %>%
  filter(Turbidity_NTU>100)

qaqc %>%
  filter(Flag_DO_mgL == 2, !is.na(DO_mgL))
```

```{r plots}

# If you try to render the file with all of plots for every year, it will run out of memory. I have run it in 3 year chunks and run 2016-2013 at one time. You can also just make the plots in the qmd with out rendering them. 

y2024 <-vars_to_plot %>%
  map(plot_var, year = 2024)

htmltools::tagList(list(y2024))

a <-vars_to_plot %>%
  map(plot_var, year = 2023)

htmltools::tagList(list(a))


b <- vars_to_plot %>%
  map(plot_var, year = 2022)

htmltools::tagList(list(b))

c <- vars_to_plot %>%
  map(plot_var, year = 2021)
htmltools::tagList(list(c))

# d <- vars_to_plot %>%
#   map(plot_var, year = 2020)
# htmltools::tagList(list(d))
# 
# e <- vars_to_plot %>%
#   map(plot_var, year = 2019)
# htmltools::tagList(list(e))
# 
# f <- vars_to_plot %>%
#   map(plot_var, year = 2018)
# htmltools::tagList(list(f))
# 
# g <- vars_to_plot %>%
#   map(plot_var, year = 2017)
# htmltools::tagList(list(g))


 # h <- vars_to_plot %>%
 #   map(plot_var, year = 2016)
 # htmltools::tagList(list(h))
 # 
 # i <- vars_to_plot %>%
 #   map(plot_var, year = 2015)
 # htmltools::tagList(list(i))
 # 
 # j <- vars_to_plot %>%
 #   map(plot_var, year = 2014)
 # htmltools::tagList(list(j))
 # 
 # k <- vars_to_plot %>%
 #   map(plot_var, year = 2013)
 # htmltools::tagList(list(k))


```

```{r SHR and GWR}

# Check that Spring Hollow and Gateweood Reservoir data look good

aa <- vars_to_plot %>%
  map(plot_var, year= c(2013:2017, 2019), reservoirs="SHR")

# when you render the document then the interactive plots will work
htmltools::tagList(list(aa))

bb <- vars_to_plot %>%
  map(plot_var, year=2016, reservoirs="GWR")

# when you render the document then the interactive plots will work
htmltools::tagList(list(bb))

```

```{r hist}

# look at the histogram of the time that casts were taken each year. Change the year in line 175. 
qaqc %>%
  select(DateTime, SN) %>%
  unique() %>%
  filter(year(DateTime) == 2024) %>%
  ggplot(aes(x = hour(DateTime))) +
  geom_histogram()+
  facet_wrap(~SN)

```
