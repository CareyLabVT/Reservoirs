---
title: "Stage_QAQC"
author: "AEB and DXH"
date: "2026-01-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyverse)
library(httr2)
library(jsonlite)
library(ggplot2)
library(plotly)
library(googlesheets4)
library(ggpmisc) #stat poly line
library(lubridate)

```

## Import all PT data

Pull all .csv files of direct data downloads from PT

```{r load data, echo = TRUE}

#Identify which GitHub Folder to pull folder names from
url <- "https://api.github.com/repos/CareyLabVT/ManualDownloadsSCCData/contents/CCR_manual_downloads/CCR_Hobos/HPB_waterlevel"

#create list of file names
resp <- request(url) |>
  req_headers(Accept = "application/vnd.github+json") |>
  req_perform()

dat <- resp_body_json(resp, simplifyVector = TRUE)

file_names <- dat$name

#only select .csv files and 2024 PT ##FOR NOW
file_names <- file_names[grepl("\\.csv$", file_names)]

#add to link 
git_link <- "https://raw.githubusercontent.com/CareyLabVT/ManualDownloadsSCCData/master/CCR_manual_downloads/CCR_Hobos/HPB_waterlevel/"

file_names <- paste0(git_link, file_names)

#import .csv files
hobo_raw <- bind_rows(
  lapply(file_names, function(f) {

    df <- read_csv(
      f,
      skip = 1,
      locale = locale(encoding = "UTF-8"),
      show_col_types = FALSE
    )

    df |>
      select(
        DateTime_EDT = contains("Date Time"),
        HOBO_Abs_Pres_kPa = contains("Abs Pres"),
        Temp_C = contains("Temp")
      ) |>
      mutate(
        DateTime_EDT = parse_datetime(DateTime_EDT, format = "%m/%d/%y %I:%M:%S %p"),
        HOBO_Abs_Pres_kPa = as.numeric(HOBO_Abs_Pres_kPa),
        Temp_C = as.numeric(Temp_C),
        )
  })
)

```

## Manage Data

Set Timezone, Column names, data types

```{r Data wrangling, echo = TRUE}
#rename column names
# hobo_raw <- hobo_raw|>
#   rename(DateTime_EDT = "DateTime_EDT",
#          HOBO_Abs_Pres_kPa = "HOBO_Abs_Pres_kPa",
#          Temp_C = "Temp_C")

#format datetime data
# hobo_raw <- hobo_raw |> 
#   mutate(DateTime_EDT = mdy_hms(DateTime_EDT))

#Set tz to EST for PT data
#force timezone to be UTC-4 since that's what the sensor was set at. Using 'American/Virgin' since EDT wasn't recognized and Virgin Islands don't use daylight savings so are always UTC-4
hobo_raw$DateTime_EDT <- force_tz(as.POSIXct(hobo_raw$DateTime_EDT), tzone = "America/Virgin")

#check that it worked
attr(hobo_raw$DateTime_EDT, "tzone")

#now need to convert from EDT to EST to line up with met data
hobo_raw$DateTime_EST <- as.POSIXct(hobo_raw$DateTime_EDT, tz = "EST")

#check that it worked
attr(hobo_raw$DateTime_EST, "tzone")

#select useful columns 
hobo_raw <- hobo_raw |>
  select(DateTime_EST,HOBO_Abs_Pres_kPa,Temp_C)

#arrange by datetime
hobo_raw <- hobo_raw |>
  arrange(DateTime_EST)

#remove rows with NAs in Temp/Pressure
hobo_raw <- hobo_raw %>% 
  filter(!is.na(HOBO_Abs_Pres_kPa), !is.na(Temp_C))

#remove duplicate times and rows with NA in pressure or temp
hobo_raw <-  hobo_raw %>%
  distinct(DateTime_EST, .keep_all = TRUE) 

```
## Look at data before correcting for barometric pressure/maintenence log
This is just a check to make sure all raw data came in and looks like it should

```{r Raw data plot, echo = TRUE}
ggplot(data = hobo_raw, aes(x = DateTime_EST)) +
  geom_line(aes(y = HOBO_Abs_Pres_kPa)) +
  scale_x_datetime()
  
ggplot(data = hobo_raw, aes(x = DateTime_EST)) +
  geom_line(aes(y = Temp_C)) +
  scale_x_datetime()

```

## Assign flags
Flags for dataset are:
0: good data
1: Sensor was out of water (maintenance, low water level, below freezing), value set to NA
2: non-active PT setup, see methods for timeline
#3: Barometric Pressure sensor data had a flag (no dangerous looking flags for now)
4: Correction applied


```{r maintenance log, echo = TRUE}
#Load maintenance log
#maint_log <- read_csv("https://raw.githubusercontent.com/CareyLabVT/Reservoirs/master/Data/DataAlreadyUploadedToEDI/EDIProductionFiles/MakeEML_CC#R_Inflow/2024/hpb_maintenancelog_2024.csv")

#Local one for now
maint_log <- read_csv("C:\\Users\\abate\\OneDrive\\Desktop\\hpb_maintenancelog_2024.csv")

#force Maintenance Log into EST tz
maint_log$TIMESTAMP_start <- force_tz(as.POSIXct(maint_log$TIMESTAMP_start, format = "%m/%d/%Y %H:%M"), tzone = "EST")
maint_log$TIMESTAMP_end <- force_tz(as.POSIXct(maint_log$TIMESTAMP_end, format = "%m/%d/%Y %H:%M"), tzone = "EST")

#Check to make sure tz changed
attr(maint_log$TIMESTAMP_start, "tzone")
attr(maint_log$TIMESTAMP_end, "tzone")

#add column for flags and set to 0 initially
hobo_raw$Flag <- 0

#Add flags from maintenance log
hobo_qaqc <- hobo_raw %>%
  rowwise() %>%
  mutate(
    Flag = {
      #find dates with flags
      maint_flag <- maint_log$flag[
        DateTime_EST >= maint_log$TIMESTAMP_start &
        DateTime_EST <= maint_log$TIMESTAMP_end
      ]
      #If not in maintenance log, keep existing flag, otherwise concat
      if(length(maint_flag) == 0){
        Flag
      } else {
        as.numeric(paste0(maint_flag, collapse = ""))
        }
          }
  ) %>%
  ungroup()

#Set Flag to 1 for any PT readings or Temp < 0 
hobo_qaqc$Flag <- if_else(hobo_qaqc$Temp_C <= 0 | hobo_qaqc$HOBO_Abs_Pres_kPa <= 0, 1, hobo_qaqc$Flag)

#remove Pressure and Temp data for Flag 1 
hobo_qaqc <- hobo_qaqc %>%
  mutate(
    HOBO_Abs_Pres_kPa = if_else(
      Flag == 1, NA_real_, HOBO_Abs_Pres_kPa, missing = HOBO_Abs_Pres_kPa
    ),
    Temp_C = if_else(
      Flag == 1, NA_real_, Temp_C, missing = Temp_C
    )
  )


```

## Correct pressure data with Barometric Pressure from met station on dam
The HOBO PTs are not vented. This corrects to local air pressure fluctuations.

```{r Correct for barometric pressure, echo = TRUE}
# ccr_met_edi <- read_csv("https://pasta.lternet.edu/package/data/eml/edi/1105/3/df0ce4fc90f220b65c400b997abae37b" )
# ccr_met_git <- read_csv("https://raw.githubusercontent.com/FLARE-forecast/CCRE-data/refs/heads/ccre-dam-data-qaqc/ccre_met_L1.csv")

ccr_met <- read_csv("C:\\Users\\abate\\Downloads\\ccr_met.csv")
#ccr_met <- read_csv("C:/Users/dwh18/Downloads/ccrmet_edi_git_hold.csv")

# ccr_met <- ccr_met_edi |>
#   select(-starts_with("Note")) |> #remove note columns to bind
#   rbind(ccr_met_git)

#write.csv(ccr_met, "C:\\Users\\abate\\Downloads\\ccr_met.csv", row.names = F)

ccr_met <- ccr_met |> 
  select(DateTime, BP_Average_kPa, Flag_BP_Average_kPa, Rain_Total_mm) |> #check BP flag
  mutate(Date = as.Date(DateTime),
         Hour = hour(DateTime),
         Min = minute(DateTime)) |> 
  filter(Min %in% c(0,10,20,30,40,50)) |>  #get just minutes to line up w/ HOBO
  rename(DateTime_EST = DateTime) |>
  select(DateTime_EST, BP_Average_kPa, Flag_BP_Average_kPa, Rain_Total_mm)

#force into correct time zone (EST)
ccr_met$DateTime_EST <- force_tz(as.POSIXct(ccr_met$DateTime_EST), tzone = "EST")

#check that it worked
attr(ccr_met$DateTime_EST, "tzone")

#correct to water level data
waterlevel_correct <- left_join(hobo_qaqc, ccr_met, by = "DateTime_EST") |> 
  mutate(corrected_Pres_kPa = HOBO_Abs_Pres_kPa - BP_Average_kPa) |> 
  mutate(waterlevel_cm = corrected_Pres_kPa * 10.1972) |>
  select(DateTime_EST, waterlevel_cm, Temp_C, Flag)#convert pressure to water depth


```

##Plot atmospheric BP corrected water level

In this zoomed in section, you can see 6/11 something happpened-- people were in the field and the sensor must have been placed differently than before. Since each subsequent visit wasnt an issue, it was probably that the PT was either not seated correctly at first deployment or got jostled and moved during a large event. 

```{r Plot BP corrected, echo = TRUE}
# waterlevel_correct |> 
#   ggplot()+
#   geom_line(aes(x=DateTime_EST, y = BP_Average_kPa, color = "MET"))+  
#   geom_line(aes(x=DateTime_EST, y = HOBO_Abs_Pres_kPa, color = "HOBO_raw"))+
#   geom_line(aes(x=DateTime_EST, y = corrected_Pres_kPa + 95, color = "HOBO_correct + 95"))

a <- waterlevel_correct |> 
  ggplot(aes(x = DateTime_EST, y = waterlevel_cm))+
  geom_point() +
  coord_cartesian(
    xlim = c(ymd_hms("2025-04-16 00:00:00"), ymd_hms("2025-06-11 23:59:59")))
#ggplotly(a)
a

```

##View with manual stage measurements

```{r}

#Pull manual stage measurement file
stage_checks <-  gsheet::gsheet2tbl("https://docs.google.com/spreadsheets/d/1OOh1QfOad3ez_Hk4Sl8ziPYxmWWcoSv1GNeuJkrFec8/edit?gid=0#gid=0")

#format date column
stage_checks$DateTime_EST = lubridate::parse_date_time(stage_checks$DateTime, orders = c('ymd HMS','ymd HM','ymd', 'mdy','mdy HM', 'mdy HMS', 'mdy HM'), tz = "America/New_York")

#set to closest 10 min to match up with PT readings
stage_checks <- stage_checks |>
  mutate(DateTime_EST = floor_date(DateTime_EST, unit = "10 minutes"))

a <- full_join(waterlevel_correct, stage_checks, by = "DateTime_EST") |> 
  ggplot(aes(x = DateTime_EST)) +
  geom_point(aes(y = waterlevel_cm)) +
  geom_point(aes(y = manual_depth_cm), color = "red") +
  coord_cartesian(
    xlim = c(ymd_hms("2024-08-01 00:00:00"), ymd_hms("2024-10-15 17:59:59")))
ggplotly(a)

ggplot(data = hobo_qaqc, aes(x = DateTime_EST)) +
  geom_point(aes(y = Temp_C)) +
  #geom_point(aes(y = manual_depth_cm), color = "red") +
  coord_cartesian(
    xlim = c(ymd_hms("2024-08-01 00:00:00"), ymd_hms("2024-08-15 17:59:59")))

compare <- full_join(stage_checks, waterlevel_correct, by = "DateTime_EST") %>%
  select(DateTime_EST, waterlevel_cm, manual_depth_cm)


#Filter to pull dates from each specific PT deployment
PT1 <- compare %>%
   filter(DateTime_EST >= as.POSIXct("2024-04-23", tz = "America/New_York"),
         DateTime_EST <= as.POSIXct("2024-12-02", tz = "America/New_York"))

PT2 <- compare %>%
   filter(DateTime_EST >= as.POSIXct("2025-03-01", tz = "America/New_York"),
         DateTime_EST <= as.POSIXct("2025-12-02", tz = "America/New_York"))

#Plot comparison of PT to manual measured stage for 1st PT deployment
ggplot(data = PT1, aes(x = waterlevel_cm, y = manual_depth_cm))+ 
  geom_point()+
  stat_poly_line(method = "lm", linewidth = 2)+
  stat_poly_eq(formula=y~x, label.x = "left", label.y="top", parse=TRUE, inherit.aes = F,
               aes(x = waterlevel_cm, y = manual_depth_cm, label=paste(..adj.rr.label..,..p.value.label..,sep="~~~"),size=3))+
  labs(title = "PT1")

#Plot comparison of PT to manual measured stage for 2nd PT deployment
ggplot(data = PT2, aes(x = waterlevel_cm, y = manual_depth_cm))+ 
  geom_point()+
  stat_poly_line(method = "lm", linewidth = 2)+
  stat_poly_eq(formula=y~x, label.x = "left", label.y="top", parse=TRUE, inherit.aes = F,
               aes(x = waterlevel_cm, y = manual_depth_cm, label=paste(..adj.rr.label..,..p.value.label..,sep="~~~"),size=3))+
  labs(title = "PT2")


```
##Correct to manual measurements
This section will eventually correct PT sensor data to manual measurements as needed. For the first two deployments, the manual measurements were in reference between a cobble bottom and riffle surface, so I don't think it is worth correcting to. TBD what to do about negatives 

PT 1 might show that the PT was slightly under the cobbles bc it was dug in with the stilling well, but imo not enough of a consistent offset to correct for. Negative values during this deployment look real (ie still tracking water, but the reference 0 is too high/flow between cobbles but not overtop. I think fine to leave, esp if they generally match up with the timline you have for disconnected flow in the stream.

PT 2 seems to have a bias towards deeper manual measurements than PT readings --all being fairly significant differences. Again, I would not correct for each manual measurement, but bc of the fairly regular looking "negative" stages, I picked a consistent offset to apply. This will also help our agreement with the manual measurements.

I think PT 1 and PT 2 stage data is useful for event timing and relating general magnitude of events. 

```{r}
selected_compare <- compare |>
  filter(!is.na(waterlevel_cm), !is.na(manual_depth_cm))

selected_compare$difference <- selected_compare$waterlevel_cm - selected_compare$manual_depth_cm

ggplot(data = selected_compare, aes(x = DateTime_EST, y = difference))+
  geom_point()+
  ylab("PT - manual depth (cm)")

```
##Correct PT2 with constant offset
Both measured values between PT downloads show large differences (-13.6 cm and -15.17 cm off), apply a constant offset (+ 10.2 cm) to the PT data to match up the data after it is reinserted on 6/11

*try to incorporate into the maintenance log so it can be a coded correction if it happens again?

```{r}
start_offset <- as.POSIXct("2025-04-11 13:10", tz = "EST")
end_offset <- as.POSIXct("2025-06-11 12:10", tz = "EST")
  
waterlevel_corrected <- waterlevel_correct |>
  mutate(
    waterlevel_cm = if_else(
      DateTime_EST >= start_offset & DateTime_EST <= end_offset, 
      waterlevel_cm + 10.2,
      waterlevel_cm
    )
  )

a <- ggplot()+
  geom_point(aes(x = waterlevel_corrected$DateTime_EST, y = waterlevel_corrected$waterlevel_cm)) +
  geom_point(aes(x = waterlevel_correct$DateTime_EST, y = waterlevel_correct$waterlevel_cm), color = "red") +
  coord_cartesian(
    xlim = c(ymd_hms("2025-06-11 00:00:00"), ymd_hms("2025-06-12 17:59:59")))
#ggplotly(a)
a
```



##Correct to Manual Measurements
This section can eventually be written to correct PT data to the manually measured water levels

##Visualize final corrected data

##Visualize qaqc parameters ie manual measurements, temp
Use this graph to visually qaqc PT data-- 
  1. When PT comes out of the water as seen by drastic temp change/larger diurnal swings and flat lining of PT data
  2. When site visit measurements don't line up with PT data
  3. 
  
  
```{r}

a <- ggplot(data = waterlevel_corrected, aes(x = DateTime_EST)) +
  geom_point(aes(y = waterlevel_cm)) +
  geom_point(aes(y = Temp_C), pch = 2, size = 0.25, color = "blue") +
  coord_cartesian(
    xlim = c(ymd_hms("2024-07-14 00:00:00"), ymd_hms("2024-09-17 23:59:59")))
#ggplotly(a)
a
```


## Visualize stage with local precip data

```{r Compare with precip, echo = TRUE}
rain_comp <- left_join(waterlevel_corrected, ccr_met, by = "DateTime_EST")

# ggplot(data = rain_comp, aes(x = DateTime_EST)) +
#   geom_line(y = waterlevel_correct) 
  #geom_point(y = rain_comp$Rain_Total_mm)


ggplot(data = rain_comp, aes(x = DateTime_EST)) +
  geom_line(aes(y = waterlevel_cm)) +
  geom_col(aes(y = Rain_Total_mm*10), color = "blue") #x 10 rain for better viewing
  scale_x_datetime()
  
```


```{r}
a <- waterlevel_correct |> 
  ggplot(aes(x = DateTime_EST, y = waterlevel_cm))+
  geom_point() +
  coord_cartesian(
    xlim = c(ymd_hms("2025-04-16 00:00:00"), ymd_hms("2025-06-11 23:59:59")))
#ggplotly(a)
a

#Pull in nearby USGS gage to compare peak shape
#data retrieval from USGS (Tinker Creek nr Daleville)
# library(dataRetrieval)
# USGSFlow = read_waterdata_daily(monitoring_location_id = "02055100", parameter_code = "00060")
# USGSFlow = renameNWISColumns(USGSFlow)
# 
# #format date column, daily average, so tz +/- a bit not a big deal
# USGSFlow$Date <- as.POSIXct(USGSFlow$Date, tz = "EST")
# USGSFlow <- rename(USGSFlow, DateTime_EST = Date)
# USGSFlow$Flow <- as.numeric(USGSFlow$Flow)
# #head(USGSFlow)
# 
# #match to our data
# USGSFlow <- left_join(waterlevel_corrected, USGSFlow, by = "DateTime_EST")

# ggplot(data = USGSFlow, aes(x = DateTime_EST)) +
#   geom_point(aes(y = waterlevel_cm)) +
#   geom_point(aes(y = USGSFlow))
#not plotting well rn-- probably scale or data type issues? 
```

