---
title: "CCR Catwalk Plots for EDI"
author: "Adrienne Breef-Pilz"
output: html_document
theme: null
original date: Jan. 2023
date: "`r Sys.Date()`"
---

This script is the visual inspection scripts. 

1. QAQCs all the raw data or for a reviewer reads in the data file from EDI for checking. 

2. Then the script checks for duplicates, daily, and subdaily gaps in the current file. 

3. Lists the flag frequency to check if there are any NAs or any assigned the wrong flag. 

4. Checks to see if the Maintenance Log is working correctly by inspecting rows in the data frame. 

5. If necessary can QAQC data already on EDI using the QAQC function

6. Creates plots

7. Writes data to new csv

8. Downloads necessary files for EDI publishing

For the plots, they use a function called "all_plot". In all_plot you can specify if you want plotly plots for the current data. BEWARE if you turn on the plotly plots and try to knit the markdown it will fail! I am working on a fix. For right now you can specify which plotly plots you want on. You can also look at the plotly plots manually in each chunk by running the chunk with Use_plotly=TRUE as an argument and then at the end of the chunk output[[1]]. 


All files are from GitHub or EDI and the source scripts are from GitHub as well. 

If you are REVIEWING this data package, add the pasta URL from EDI in the "Bind Historical and L1 files together". Make sure to comment out the row_bind section and un comment the section that reads in the pasta. In addition, make sure eval=FALSE is in the chunk header for "Read in EDI Files", "Read in current L1 file", "Make new CSV with current and historic files" chunk and "Download and save Maintenance Log". These chunks of code will not be run when the R markdown is knitted together. Once that is all set than you can knit the file together as an HTML file to look at all the plots. 

```{r Set Up, include=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(RCurl,devtools, tidyverse,lubridate, plotly, magrittr, scattermore, knitr, htmltools, pander)

# Source scripts from GitHub
# Function to make the QAQC . This is called CCRCatwalk_qaqc_2023_2023.R in the EDI data package. 
devtools::source_url('https://raw.githubusercontent.com/FLARE-forecast/CCRE-data/ccre-dam-data-qaqc/R/edi_qaqc_function.R')


# Function to make the plots below
devtools::source_url('https://raw.githubusercontent.com/CareyLabVT/Reservoirs/master/Data/DataAlreadyUploadedToEDI/EDIProductionFiles/Plotting_function.R')


 #turn off pander auto asis. Used for making the ploty functions show up in the knitted markdown HTML
        pander::panderOptions('knitr.auto.asis', FALSE)

# Set up the current time end time of the file and the current year for QAQC plots

#current time of QAQC for graphing
current_time_start=ymd_hms("2023-01-01 00:00:00", tz = "EST")
current_time_end= ymd_hms("2023-12-31 23:59:00", tz = "EST")
```

```{r QAQC all Files, eval=FALSE, include=FALSE}

# QAQC all the raw files using the QAQC function which is sourced above. It is also the same function CCRCatwalk_qaqc_2021_2023.R which is included in the data package

# current_df <-qaqc_ccr(
#     data_file = 'https://raw.githubusercontent.com/FLARE-forecast/CCRE-data/ccre-dam-data/ccre-waterquality.csv',
#     data2_file = 'https://raw.githubusercontent.com/CareyLabVT/ManualDownloadsSCCData/master/CCR_manual_downloads/CCRWaterquality_L1_2021_2023.csv' ,
#     EXO2_manual_file = 'https://raw.githubusercontent.com/CareyLabVT/ManualDownloadsSCCData/master/CCR_manual_downloads/CCRCatwalk_EXO_manual_2021_2023.csv',
#     maintenance_file = 'https://raw.githubusercontent.com/FLARE-forecast/CCRE-data/ccre-dam-data-qaqc/CCRW_MaintenanceLog.csv',
#     output_file = NULL,
#     start_date = ymd_hms("2021-04-09 15:20:00", tz="EST"), # This is when we want the file to start
#     end_date = Sys.Date()
# )

```

REVIEWERS- If you are reviewing this data package replace the pasta link with the one from EDI. If there are questions ask the data point person. 

```{r Bind files together or READ IN EDI FOR REVIEWER, include=FALSE}
  
# # If No EDI file exists with all the years you want to look at
#   current_df <- current_df%>%
#   dplyr::distinct()%>% # get rid of dups if they snuck in 
#   filter(DateTime<(current_time_end))
# 
# 
# # make sure no time duplicates. 
#  current_df<-  current_df[!duplicated(current_df$DateTime), ]
# 
# #reorder. Just to be certain everything is in order
#   current_df<-current_df[order(current_df$DateTime),]

# For REVIEWERS: Run this section to pull the data from EDI which is in staging as a check of the data.
# MAKE SURE TO UPDATE THE PASTA FROM THE VERSION YOU WANT
  
  
                                                                   ### CHANGE THIS NUMBER BELOW 
                                                                               ##      
   current_df <-read_csv("https://pasta-s.lternet.edu/package/data/eml/edi/719/24/b7e4a95bf842e24c77cfd23dfee543cd")
 # 
 # # Force files from EDI to have an EST timestamp
   current_df$DateTime <- ymd_hms(current_df$DateTime, tz = "EST")

```

## Information for EDI methods text
This is information that is included in the methods file for EDI 

The minimum water level for CCR was `r min(current_df$LvlDepth_m_13, na.rm=T)` and the maximum water depth was `r max(current_df$LvlDepth_m_13, na.rm=T)`.

The median water level was `r median(current_df$LvlDepth_m_13, na.rm=T)` and the mean water level was `r mean(current_df$LvlDepth_m_13, na.rm=T)`.


```{r Download Raw data for plotting, include=FALSE}

# This is the raw files from the data logger before qaqc. I like to plot this with the qaqc values so we can see what has been removed by the qaqc function and maint log and what has been missed. 

CATPRES_COL_NAMES = c("DateTime", "RECORD", "CR3000Battery_V", "CR3000Panel_Temp_C", 
                        "ThermistorTemp_C_1", "ThermistorTemp_C_2", "ThermistorTemp_C_3", "ThermistorTemp_C_4",
                        "ThermistorTemp_C_5", "ThermistorTemp_C_6", "ThermistorTemp_C_7", "ThermistorTemp_C_8",
                        "ThermistorTemp_C_9","ThermistorTemp_C_10","ThermistorTemp_C_11", "ThermistorTemp_C_12",
                        "ThermistorTemp_C_13","EXO_Date_1", "EXO_Time_1", "EXOTemp_C_1", "EXOCond_uScm_1",
                        "EXOSpCond_uScm_1", "EXOTDS_mgL_1", "EXODOsat_percent_1", "EXODO_mgL_1", "EXOChla_RFU_1",
                        "EXOChla_ugL_1", "EXOBGAPC_RFU_1", "EXOBGAPC_ugL_1", "EXOfDOM_RFU_1", "EXOfDOM_QSU_1",
                        "EXOPressure_psi_1", "EXODepth_m_1", "EXOBattery_V_1", "EXOCablepower_V_1", "EXOWiper_V_1",
                        "EXO_Date_9", "EXO_Time_9", "EXOTemp_C_9", "EXOCond_uScm_9",
                        "EXOSpCond_uScm_9", "EXOTDS_mgL_9", "EXODOsat_percent_9", "EXODO_mgL_9", 
                        "EXOfDOM_RFU_9", "EXOfDOM_QSU_9","EXOPressure_psi_9", "EXODepth_m_9", "EXOBattery_V_9",
                        "EXOCablepower_V_9", "EXOWiper_V_9","LvlPressure_psi_13", "LvlTemp_C_13")
  
 
  # read catwalk data and maintenance log
  # NOTE: date-times throughout this script are not specified but they are all processed in the same timezone 
  raw <- read_csv("https://raw.githubusercontent.com/FLARE-forecast/CCRE-data/ccre-dam-data/ccre-waterquality.csv", skip = 1, col_names = CATPRES_COL_NAMES,
                      col_types = cols(.default = col_double(), DateTime = col_datetime()))
  
  
  # Take out extremly high values, EXO_Date and Time, and create depth column
   raw <- raw%>%
     select(-c("EXO_Date_1", "EXO_Time_1", "EXO_Date_9", "EXO_Time_9"))%>%
      mutate(across(ThermistorTemp_C_1:LvlTemp_C_13, ~ifelse(.x >180, NA, .x)))%>%
       mutate(LvlDepth_m_13=LvlPressure_psi_13*0.70455)#1psi=2.31ft, 1ft=0.305m

  # convert NaN to NAs in the dataframe
  raw[sapply(raw, is.nan)] <- NA
  
  # Force historical file timestamp to EST
  raw$DateTime <- force_tz(as.POSIXct(raw$DateTime), tzone = "EST")
 

```

## Check for duplicates and  gaps in the data frame

This section identifies if there are any duplicates, daily data, and sub daily gaps in the long-term record. If there are duplicates. Look to see if they are true duplicates and then check the qaqc function and the chunk above where duplicates should be removed. 


### Are there any duplicates?


```{r Check for dups , echo=FALSE}

# Make sure there are no duplicated dates. Do this here because the file is too large for Data Explore.
# Print them if there are
 dups<- current_df[duplicated(current_df$DateTime), ]

dups <- dups%>%
  select(DateTime, RECORD, ThermistorTemp_C_7,  
         EXOTemp_C_1, EXOTemp_C_9, LvlPressure_psi_13)

# Make it into a nice table when the Markdown is knitted together
knitr::kable((dups))
```


### Are there any gaps in the data file?


When gaps are found in the data file, check that you do not have new gaps in the previous years' publication. For the current year, if you find gaps check that you have all of the manually downloaded files. If the data are truly missing then record the dates and times in the methods section. 

```{r Check for Gaps larger than a day, echo=FALSE}
# Check if there are daily gaps in the data. If there are record them in the 
# Get DOY
ccrwater <- current_df
 ccrwater$DOY=yday(ccrwater$DateTime)

 for(i in 2:nrow(ccrwater)){ #this identifies if there are any data gaps in the long-term record, and where they are by record number
    if(ccrwater$DOY[i]-ccrwater$DOY[i-1]>1){
      print(c(ccrwater$DateTime[i-1],ccrwater$DateTime[i]))
    }
 }
```

This identifies if there are any sub-daily gaps in the current record which gets recorded in the methods section. 

The first row is the time for the first observation and then the subsequent observation. Each observation should be 10 minutes apart. The second row is the number of the record for each observation. Most of these gaps happen when we change the program on the data logger. These times will be recorded in the maintenance section of the metadata and are also noted in the maintenance log.

```{r Check for sub daily gaps, echo=FALSE}

# Because we can't have NAs for this for loop let's make a new df
 ccr2 <- current_df%>%
  filter(!is.na(RECORD))%>%
  filter(DateTime>current_time_start)

  for(i in 2:length(ccr2$RECORD)){ #this identifies if there are any data gaps in the long-term record, and where they are by record number
    if( abs(ccr2$RECORD[i]-ccr2$RECORD[i-1])>1 & difftime(ccr2$DateTime[i], ccr2$DateTime[i-1], units="mins")>10){
      print(c(ccr2$DateTime[i-1], ccr2$DateTime[i]))
      print(c(ccr2$RECORD[i-1], ccr2$RECORD[i]))
    }
  }
```
 

### Flag Frequency
Let's look at the flag Frequency for each variable. As a reminder here are the flag codes
 Flag values
 
 0: no flag
 
 1: value removed due to maintenance and set to NA
 
 2: negative or outlier value removed and set to NA, see Methods section for more detail on QAQC process
 
 3: negative values set to 0 except for temperature
 
 4: value removed due to fouling and set to NA
 
 5: questionable value but left in the dataset
 
 6: Values adjusted using a linear or square root function to match high-resolution CTD profiles and corrected other affected observations on the same sensor
 
 7: missing data
 
```{r Check out the flags, echo=FALSE}



#make sure no NAS in the Flag columns
Flags <- current_df%>%
  select(DateTime, starts_with("Flag"))

RowsNA=Flags[!complete.cases(Flags), ] # Keep only the complete rows

#check the flag column
Flags <- current_df%>%
  select(starts_with("Flag"))

# Make a table with the number of times a flag was used
for(f in 1:ncol(Flags)){
  print(colnames(Flags[f]))
  print(table(Flags[,f], useNA = "always"))
}
```


### Check to make sure that what is in the maintenance log was actually removed

### Look at the last rows of the maintenance log 

We want to make sure that our maintenance log actually worked and took out the values or changes those it was supposed to 

```{r Read in the maintenance log and look at the tail, echo=FALSE}

 maint <- read_csv2("https://raw.githubusercontent.com/FLARE-forecast/CCRE-data/ccre-dam-data-qaqc/CCRW_MaintenanceLog.csv",
                    show_col_types = FALSE)


# name the data file for just the tail of the maintenance log
# you want to filter out 7 because that is if the observation is missing and there are other ways that is flagged in the data besides the maintenance log, so it is not a good check.
sd <- tail(maint)%>%
  filter(flag!=7)


knitr::kable((tail(sd)))

```
#### Check the that the columns have flags 

Look at the first few rows of the data frame and check that the observations after the TIMESTAMP_start are flagged

#### Look at the first 5 rows for that time

```{r Did the maint log work head, echo=FALSE, message=FALSE, warning=FALSE}
# get the last row of the data file
last_row <- tail(sd, n=1)

# Get starttime and end time
### get start and end time of one maintenance event
    start <- force_tz(as.POSIXct(last_row$TIMESTAMP_start), tzone = "EST")
    end <- force_tz(as.POSIXct(last_row$TIMESTAMP_end), tzone = "EST")
    
    # Get the time of the maintenance
    if(is.na(end)){
      # If there the maintenance is on going then the columns will be removed until
      # and end date is added
      Time <- current_df |> filter(DateTime >= start) |> select(DateTime)
      
    }else if (is.na(start)){
      # If there is only an end date change columns from beginning of data frame until end date
      Time <- current_df |> filter(DateTime <= end) |> select(DateTime)
      
    }else {
      Time <- current_df |> filter(DateTime >= start & DateTime <= end) |> select(DateTime)
    }


### Get the names of the columns affected by maintenance
    colname_start <- last_row$start_parameter
    colname_end <- last_row$end_parameter
    
    # Make list of just the columns we want 
    
    test <- colnames(current_df%>%select(DateTime, colname_start, paste0("Flag_",colname_start), colname_end, paste0("Flag_",colname_end)))
    
    # Print the head of the table to make sure that data are flagged
    
    knitr::kable((head(current_df[current_df$DateTime %in% Time$DateTime, test]))) 

```

#### Look at the last 6 rows for the maintenance time

Make sure the observations are flagged

```{r Print the tails, echo=FALSE, message=FALSE, warning=FALSE}

# Print the tail of the table to make sure that data are flagged
    
    knitr::kable(tail(current_df[current_df$DateTime %in% Time$DateTime, test])) 

```

### Subset and rename the files
This section will subset the files so you can make plots of the whole time series and the current year. 
Here we also get the daily average for each variable so we can make box plots and density plots to look at the data over time. 

```{r Filter for current year and daily average, include=FALSE}

# Raw files
current_raw <- raw%>%
  filter(DateTime>=current_time_start & DateTime<current_time_end)%>%
  mutate(type = "raw")

current <- current_df%>%
  filter(DateTime>=current_time_start & DateTime<current_time_end)%>%
  mutate(type = "qaqc")%>%
  select(DateTime:CR3000Panel_Temp_C,type, -contains("adjusted"))


# Let's only keep values that are different instead of plotting the raw and the qaqc value
current_plot_df <- bind_rows(current, current_raw)%>%
  dplyr::distinct(across(DateTime:LvlDepth_m_13), .keep_all = T)
    

daily <- current_df%>% 
  group_by( Date = as.Date(DateTime)) %>% 
  summarise_if(is.numeric, mean, na.rm=T)%>%
  mutate(Year = as.factor(year(Date)),
         Month = month(Date),
         Time = "12:00:00")%>%
  mutate(DateTime= paste0(Date, Time, sep=" "))%>%
  mutate(DateTime=ymd_hms(DateTime))

  
# current_df <- current_df%>%
#   mutate(Year=year(DateTime))

colors <- c("raw" = "red", "qaqc" = "black")
# colors for comparing Thermistor, RDO and Pressure sensor
colors2 <- c("Therm"="magenta","RDO"="dodgerblue2" ,"Pressure"="black")
```



## QAQC Plots

##### QAQC plot information and all_plot function information

For the plots, they use a function called "all_plot". In all_plot you can specify if you want plotly plots for the current data. BEWARE if you turn on the plotly plots and try to knit the markdown it will fail! I am working on a fix. For right now you can specify which plotly plots you want on. You can also look at the plotly plots manually in each chunk by running the chunk with Use_plotly=TRUE as an argument and then at the end of the chunk output[[1]]. 

The plotting function is called all_plot() which plots the 4 or more plots described below. The function is sourced from GitHub in the first chunk of the script. The argumenst are:
Var # The column you want to plot. Make sure it is in quotes
y_lab,  # This label can take an expression aka have the proper degrees C, 
y_lab2, # This label is for the plotly function which can not handle expression argument. 
Water=T, # Are these plots for inwater streaming sensors?
Raw_file = T, # Do you have access to raw files to compare to. This is only for streaming sensors. 
Use_plotly = F){ # Do you want to produce plotly interactive plots? 

The arguments with = followed by a True means that they are the defaults and you don't need to add them to the function when you use it. If you want to use the opposite of the default you must specify that. 
  
##### Plot Description:

The plots below are:
The first 2 plots are the ones you should focus on for the QAQC chec. Spend the most time looking at the most recent data because that one as been checked. Do pay attention to the historical to make sure there are no crazy outliers that were missed in previous years. 
1. A time series of the current years' data. The black dots are the qaqced observations and the red is the raw files that were qaqced. This is to see what kind of values were removed and if there are any the script missed or that need to be added to the maintenance log. 

2. A time series of the historical and the current data just the qaqced values. 

The next two plots are just fun to see trends over time with the data. 

3. Density plots are like a histogram and a grouped by color so you can see where the data are relative to other years. 

4. The box plots look at the spread of the data within the year and we can look at the median and see how that is changing or not. 

Do not over think the last 2 plots. 

There are additional plots for depths that have more than one sensor such as at position 13 that has a thermistor and a pressure transducer which both measure temperature. In this case, we plot them on top of each other to make sure they are within the ballpark. For chal and the bluegreen algae sensor on the EXO2 we plot the daily observations on top of the 10 minute observations to make sure that the daily captures the same trend as the 10 minute data. 

### Temperature

```{r Temp, echo=FALSE, results='asis'}

dx <- colnames(current%>%select(grep("Temp_C_[0-9A-Za-z]",colnames(current))))

# make the plots
outputs <- lapply(dx, all_plot,y_lab = expression(''*~degree*C*''), y_lab2 = "Degrees C", Use_plotly =F)

output <- unlist(outputs, recursive = F)

# Use this if you want to look at the plotly plot in the Markdown document. Make sure that Use_plotly = T in the all_plot function above. 

#output[[1]]

```

```{r Print plotly temp, echo=FALSE, messages=FALSE, warning=FALSE}

 # Used to print the plotly plots
  # attach the Dependencies
  # since the do not get included with renderTags(...)$html
  deps <- lapply(
    Filter(function(x){inherits(x,"htmlwidget")},output),
    function(hw){
      renderTags(hw)$dependencies
    }
  )
  
  if(length(deps)>0){
  attachDependencies(
    tagList(),
    unlist(deps,recursive=FALSE)
  )
  }  
```

##### All of the temperature plots

```{r All Temperature, echo=FALSE, warning = FALSE, results='hide'}

colors3 <-c("1"="firebrick1", "2"="DarkOrange1", "EXO_1.5m"="yellow","3"="gold", 
                                  "4"="greenyellow", "5"="medium sea green", "6"="sea green",
                                  "7"="DeepSkyBlue4", "8"="blue2", "9"="cornflowerblue", "EXO_9m"="blue4",
            "10"="darkslateblue","11"="magenta2", "12"="darkmagenta", "13"="black")


# Take out Temperature values 

  All_temp<-current_df%>%
    select(DateTime, starts_with("Ther"), starts_with("EXOTemp"), "LvlTemp_C_13")%>%
    pivot_longer(-c(DateTime), names_to="Sensor", values_to="Reading", values_drop_na=TRUE)%>%
    mutate(DateTime=ymd_hms(DateTime))
  
  
  ggplot(All_temp)+
    geom_scattermore(aes(x=DateTime, y=Reading))+
    facet_wrap(.~factor(Sensor, levels=c("ThermistorTemp_C_1", "ThermistorTemp_C_2", "EXOTemp_C_1", "ThermistorTemp_C_3", "ThermistorTemp_C_4","ThermistorTemp_C_5","ThermistorTemp_C_6","ThermistorTemp_C_7","ThermistorTemp_C_8","ThermistorTemp_C_9","EXOTemp_C_9","ThermistorTemp_C_10","ThermistorTemp_C_11","ThermistorTemp_C_12","ThermistorTemp_C_13", "LvlTemp_C_13")))+
    theme_bw()
  
  
# This is all the temps and just the current year
    ggplot(current,aes(x = DateTime))+
    geom_line(aes(y=ThermistorTemp_C_1, color="1"))+
    geom_line(aes(y=ThermistorTemp_C_2, color="2"))+
    geom_line(aes(y=EXOTemp_C_1, color="EXO_1.5m")) +
    geom_line(aes(y=ThermistorTemp_C_3, color="3"))+
    geom_line(aes(y=ThermistorTemp_C_4, color="4"))+
    geom_line(aes(y=ThermistorTemp_C_5, color="5"))+
    geom_line(aes(y=ThermistorTemp_C_6, color="6"))+
    geom_line(aes(y=ThermistorTemp_C_7, color="7"))+
    geom_line(aes(y=ThermistorTemp_C_8, color="8"))+
    geom_line(aes(y=ThermistorTemp_C_9, color="9"))+
    geom_line(aes(y=EXOTemp_C_9, color = "EXO_9m"))+
    geom_line(aes(y=ThermistorTemp_C_10, color="10"))+
    geom_line(aes(y=ThermistorTemp_C_11, color="11"))+
    geom_line(aes(y=ThermistorTemp_C_12, color="12"))+
    geom_line(aes(y=ThermistorTemp_C_13, color="13"))+
    ggtitle("Current Temperature Profile") +
    labs(y = expression(''*~degree*C*''),
           color = "Legend") +
      scale_color_manual(values = colors3)+
      theme_bw()
  
```

### Depth QAQC Plots

```{r Pressure Sensor, echo=FALSE, results='asis'}
### Plotting depth from pressure sensor 
   
dx <- colnames(current%>%select(grep("Depth_m",colnames(current))))

# make the plots
outputs <- lapply(dx, all_plot,y_lab = "Meters", y_lab2 = "Meters", Water= T, Raw_file=T, Use_plotly=F)

output <- unlist(outputs, recursive = F)

# Use this if you want to look at the plotly plot in the Markdown document. Make sure that Use_plotly = T in the all_plot function above. 

#output[[1]]

```

```{r Print plotly pres, echo=FALSE, messages=FALSE, warning=FALSE}

 # Used to print the plotly plots
  # attach the Dependencies
  # since the do not get included with renderTags(...)$html
  deps <- lapply(
    Filter(function(x){inherits(x,"htmlwidget")},output),
    function(hw){
      renderTags(hw)$dependencies
    }
  )
  if(length(deps)>0){
  attachDependencies(
    tagList(),
    unlist(deps,recursive=FALSE)
  )
  }  
```

### Dissolved Oxygen QAQC Plots

```{r DO, echo=FALSE, results='asis'}


dx <- colnames(current%>%select(grep("DO_mgL|sat_percent",colnames(current))))

# make the plots
outputs <- lapply(dx, all_plot,y_lab = "mg/L or % sat", y_lab2 = "mg/L or % sat", Water= T, Raw_file=T, Use_plotly=F)

output <- unlist(outputs, recursive = F)

# Use this if you want to look at the plotly plot in the Markdown document. Make sure that Use_plotly = T in the all_plot function above. 

#output[[1]]

```

```{r Print plotly DO, echo=FALSE, messages=FALSE, warning=FALSE}

 # Used to print the plotly plots
  # attach the Dependencies
  # since the do not get included with renderTags(...)$html
  deps <- lapply(
    Filter(function(x){inherits(x,"htmlwidget")},output),
    function(hw){
      renderTags(hw)$dependencies
    }
  )
  
  if(length(deps)>0){
  attachDependencies(
    tagList(),
    unlist(deps,recursive=FALSE)
  )
  }  
```

### Chlorophyll and Phycocanin QAQC Plots

```{r Check the EXO Chla and Blue Greens, echo=FALSE, results='asis'}

dx <- colnames(current%>%select(grep("Chla|BGAPC",colnames(current))))

# make the plots
outputs <- lapply("EXOChla_RFU_1", all_plot, y_lab = "RFU or ug/L", y_lab2 = "RFU or ug/L", Use_plotly=F)

output <- unlist(outputs, recursive = F)

# Use this if you want to look at the plotly plot in the Markdown document. Make sure that Use_plotly = T in the all_plot function above. 

#output[[1]]

```

```{r Print plotly algae, echo=FALSE, warning=FALSE, messages=FALSE}


 # Used to print the plotly plots
  # attach the Dependencies
  # since the do not get included with renderTags(...)$html
  deps <- lapply(
    Filter(function(x){inherits(x,"htmlwidget")},output),
    function(hw){
      renderTags(hw)$dependencies
    }
  )
  if(length(deps)>0){
  attachDependencies(
    tagList(),
    unlist(deps,recursive=FALSE)
  )
  }  
```

### fDOM QAQC Plots

```{r fdom EXO sensor, echo=FALSE, results='asis'}

dx <- colnames(current%>%select(grep("fDOM",colnames(current))))

# make the plots
outputs <- lapply(dx, all_plot, y_lab = "RFU or QSU", y_lab2 = "RFU or QSU",Water = T, Raw_file = T, Use_plotly=T)

output <- unlist(outputs, recursive = F)

# Use this if you want to look at the plotly plot in the Markdown document. Make sure that Use_plotly = T in the all_plot function above. 

#output[[1]]
```

```{r Print plotly fdom, echo=FALSE, messages=FALSE, warning=FALSE}

 # Used to print the plotly plots
  # attach the Dependencies
  # since the do not get included with renderTags(...)$html
  deps <- lapply(
    Filter(function(x){inherits(x,"htmlwidget")},output),
    function(hw){
      renderTags(hw)$dependencies
    }
  )
  
  if(length(deps)>0){
  attachDependencies(
    tagList(),
    unlist(deps,recursive=FALSE)
  )
  }  
```

### Conductivity, Specific Conductivity, TDS QAQC Plots

```{r Cond Spcond and TDS, echo=FALSE, results='asis'}

dx <- colnames(current%>%select(grep("^EXOSpCond|^EXOCond|^EXOTDS",colnames(current))))

# make the plots
outputs <- lapply(dx, all_plot, y_lab = "uScm or mg/L", y_lab2 = "uScm or mg/L", Water= T, Raw_file=T, Use_plotly=T)

output <- unlist(outputs, recursive = F)

# Use this if you want to look at the plotly plot in the Markdown document. Make sure that Use_plotly = T in the all_plot function above. 

#output[[1]]


```

```{r Print plotly cond, echo=FALSE, messages=FALSE, warning=FALSE}

 # Used to print the plotly plots
  # attach the Dependencies
  # since the do not get included with renderTags(...)$html
  deps <- lapply(
    Filter(function(x){inherits(x,"htmlwidget")},output),
    function(hw){
      renderTags(hw)$dependencies
    }
  )
  
  if(length(deps)>0){
  attachDependencies(
    tagList(),
    unlist(deps,recursive=FALSE)
  )
  }  
```


### Wiper, Battery, and CablePower QAQC Plots

```{r Wiper, echo=FALSE, results='asis'}

dx <- colnames(current%>%select(grep("Wiper_V|EXOBattery_V|power_V",colnames(current))))

# make the plots
outputs <- lapply(dx, all_plot, y_lab="Volts", y_lab2="Volts")

output <- unlist(outputs, recursive = F)

# Use this if you want to look at the plotly plot in the Markdown document. Make sure that Use_plotly = T in the all_plot function above. The only plotly function for this chunk is the Wiper. We don't need to have interactive plots for the others. 

#output[[1]]

```

```{r Print plotly power, echo=FALSE, messages=FALSE, warning=FALSE}

 # Used to print the plotly plots
  # attach the Dependencies
  # since the do not get included with renderTags(...)$html
  deps <- lapply(
    Filter(function(x){inherits(x,"htmlwidget")},output),
    function(hw){
      renderTags(hw)$dependencies
    }
  )
  
  if(length(deps)>0){
  attachDependencies(
    tagList(),
    unlist(deps,recursive=FALSE)
  )
  }  
```


```{r Make new CSV with current and historic files, eval=FALSE, include=FALSE}

# Double Check naming convention
# Variable_StartYear_EndYear

# convert datetimes to characters so that they are properly formatted in the output file
 current_df$DateTime <- as.character(current_df$DateTime)

write_csv(current_df, "CCRCatwalk_2021_2023.csv")

```


```{r Download and save Maintenance Log, eval=FALSE, include=FALSE}

# Maintenance Log
download.file("https://raw.githubusercontent.com/FLARE-forecast/CCRE-data/ccre-dam-data-qaqc/CCRW_MaintenanceLog.csv", "CCRCatwalk_maintenancelog_2021_2023.csv")

# qaqc function
download.file("https://raw.githubusercontent.com/FLARE-forecast/CCRE-data/ccre-dam-data-qaqc/R/edi_qaqc_function.R", "CCRCatwalk_qaqc_2021_2023.R")

# streaming plots function
download.file("https://raw.githubusercontent.com/CareyLabVT/Reservoirs/master/Data/DataAlreadyUploadedToEDI/EDIProductionFiles/Plotting_function.R", "Plot_function.R")

# Depth offsets
download.file("https://raw.githubusercontent.com/FLARE-forecast/CCRE-data/ccre-dam-data-qaqc/CCR_Depth_offsets.csv",
              "CCRCatwalk_Depth_offsets_2021_2023.csv")

# Finding depth function
download.file("https://raw.githubusercontent.com/LTREB-reservoirs/vera4cast/main/targets/target_functions/find_depths.R","find_depths.R")

# Download HOBO files from GitHub
download.file("https://raw.githubusercontent.com/CareyLabVT/ManualDownloadsSCCData/master/CCR_manual_downloads/CCR_Hobos/CCR_hobos_20_21.csv", "CCR_hobos_2020_2021.csv")

# Download the HOBO compilation script from GitHub
download.file("https://raw.githubusercontent.com/CareyLabVT/ManualDownloadsSCCData/master/CCR_manual_downloads/CCR_Hobos/CCR_hobo_compilation.R", "CCR_hobo_compilation.R")

```

