---
title: "FCR Catwalk Plots for EDI"
author: "Adrienne Breef-Pilz"
output: html_document
theme: null
created: "Jan. 2023" 
date: "`r Sys.Date()`"
edited: "Jan. 2026"
---
Updates: 
Created Jan. 2023
Dec. 2025- Added a section to update all the values needed in the markdown and made it so certain chunks will knit depending on if you are the data publisher or data reviewer. 
Jan. 2026 - Updated the arguments in the qaqc function. Didn't need the other data argument. 


This script is the visual inspection script. 

1. QAQCs all the raw data or for a reviewer reads in the data file from EDI for checking. 

2. Then the script checks for duplicates, daily, and subdaily gaps in the current file. 

3. Lists the flag frequency to check if there are any NAs or any assigned the wrong flag. 

4. Checks to see if the Maintenance Log is working correctly by inspecting rows in the data frame. 

5. Creates plots

6. Writes data to new csv

7. Downloads necessary files for EDI publishing


All files are from GitHub or EDI and the source scripts are from GitHub as well. 

INFORMATION:

There are two ways to use this script. You can either run it by chunks or you can knit it and make an html file. Knitting the file will run all the chunks and create an html page with all the plots. I recommend this because if you run it chunk by chunk your R may abort the session. The Knit button is on the top of the file with a ball of yarn and a needle next to it.

If you are REVIEWING this data package, add the pasta URL from EDI in the "EDIT HERE" chunk and you change the role, as well. If you are knitting the document, only the specified chunks of code will be run depending on your role.  Once that is all set than you can knit the file together as an HTML file to look at all the plots. 

If you are running the code chunk by chunk you might need to make some adjustments to the code. To make the plots, this markdown uses a function called "all_plots". In the function it creates a plots of the most current year, the whole times series, as well as, density and box plots for daily averages. You can also specify if you would like to produce a heat map. Note that heat maps are only produced if your data has a depth column. The function also allows you to choose if you want interactive plots, using plotly, for the most recent year of data. The plotly plots are designed to be in order with the other plots when knit to together. Therefore if you are running the ploting section, chunk by chunk, then you need to specify the plotly plot from the list of plots labeled "output". For this data package do not use plotly for all plots at one time. I usually use it for depth, oxygen, and chla. 



If you are REVIEWING this data package, got to the "EDIT HERE" chunk

1.  Update your role

2.  Update the pasta link from EDI

If you are running the code chunk by chunk you might need to make some adjustments to the code. 

FOR DATA PRODUCT LEAD:

If you are the data product lead and making the data package then:

1.  Make sure all the date ranges are up to date especially current_time_start and current_time_end.

2.  Change the years in the saved data files in "Write CSV" and "Download and save Maintenance Log" chunk.

3.  Comment out the Reviewer section and make sure for the settings eval = FALSE.

4.  Update the data frame in "Get raw files" to include the most recent file on GitHub.

5.  Knit the file. This is up to you. 

6.  Look over the plots and see if there are any issues that need to be added to the maintenance log. I will usually read in the file you just made and make smaller plots with the variable and month in question. Once I have the dates, add them to the maintenance log.

7.  Re-run the inspection script until you have found all of the issues.

8.  Run the "Download and save Maintenance Log" chunk to have the most up to date files in the EDI folder.

9.  Make sure large maintenance issues are also documented in the methods.txt file.

```{r setup packages, include=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(RCurl,devtools, tidyverse,lubridate, plotly, magrittr, scattermore, knitr, htmltools, pander)

# Source scripts from GitHub
# QAQC function
source("https://raw.githubusercontent.com/FLARE-forecast/FCRE-data/fcre-catwalk-data-qaqc/R/edi_qaqc_function.R")

# Plotting function
source('https://raw.githubusercontent.com/CareyLabVT/Reservoirs/master/Data/DataAlreadyUploadedToEDI/EDIProductionFiles/Plotting_function.R')

#source("./../../Plotting_function.R")
 #turn off pander auto asis
        pander::panderOptions('knitr.auto.asis', FALSE)
```

REVIEWERS and DATA PUBLISHERS START HERE BEFORE KNITTING

1.  Update your role

2.  Update dates for current year plots

3.  If you are a reviewer, update the edi link

```{r EDIT HERE, include=FALSE}

# 1. How would you like to use this script. If you are a data publisher write "publisher" if you are a reviewer write "reviewer"

role <- "publisher"

# 2. DATA PUBLISHERS UPDATE DATES HERE
# Set up the current time end time of the file and the current year for QAQC plots
#current time of QAQC for graphing

current_time_start=ymd_hms("2025-01-01 00:00:00", tz="EST")
current_time_end=ymd_hms("2025-12-31 23:59:00", tz="EST")

# 3. DATA PUBLISHERS UPDATE FILE NAMES
# Update the name of the data files, maintenance log, and qaqc function. Double check the name of the file matches the naming convention and the start and end date of the data file. 

file_name <- "fcre-waterquality_2018_2025.csv"

qaqc_function <- "fcre-waterquality_qaqc_2018_2025.R"

maintenance_log <- "fcre-waterquality_maintenancelog_2018_2025.csv"

# 3. For REVIEWERS: Run this section to pull the data from EDI which is in staging as a check of the data.
# # MAKE SURE TO UPDATE THE PASTA FROM THE VERSION YOU WANT

edi_link <-"https://pasta-s.lternet.edu/package/data/eml/edi/518/36/814580ebec0385c66f0a0a97c38e9136"  

```

```{r set chunks on or off, echo=FALSE}
### Code to determine which chunks are turned on and off

if(role=="publisher"){
  make_data = TRUE
  edi_stage = FALSE
}else if(role == "reviewer"){
  make_data = FALSE
  edi_stage = TRUE
}

```


```{r QAQC all files, eval=make_data, message=TRUE, warning=TRUE, echo=FALSE}

# DATA PRODUCT LEAD START HERE
# Un comment this section and if you are going to knit the document together make sure the eval=TRUE or is not in the brackets above.
# Update the argument with the new links to make the data file. This might take some other scripts to combine all the years of data for the manual downloads for the VT sensors and the WVWA sensors. Note that if you are testing/fixing some data files you can adjust them locally and link to the local ones until you are ready to push them to GitHub.

ds <- c(
  'https://raw.githubusercontent.com/FLARE-forecast/FCRE-data/fcre-catwalk-data-qaqc/fcre-waterquality_legacy_2018_2019_2020_2021_2022_2023.csv',
  'https://raw.githubusercontent.com/FLARE-forecast/FCRE-data/fcre-catwalk-data-qaqc/fcre-waterquality_legacy_2024.csv',
  # THE CURRENT YEARS FILE
  'https://raw.githubusercontent.com/FLARE-forecast/FCRE-data/fcre-catwalk-data/fcre-waterquality.csv',
  
  # manual files
  # Read in and make a data frame of the manual downloaded files. I make these each year with the raw files we have downloaded.
# See ManualDownloadsSCCData for the script on making the file for each year.
# Link here : https://github.com/CareyLabVT/ManualDownloadsSCCData/tree/master/MetStation
  "https://raw.githubusercontent.com/CareyLabVT/ManualDownloadsSCCData/master/CR6_Files/FCRcatwalk_manual_2018_2023.csv",
               "https://raw.githubusercontent.com/CareyLabVT/ManualDownloadsSCCData/master/CR6_Files/FCRCatwalk_manual_2024.csv",
               "https://raw.githubusercontent.com/CareyLabVT/ManualDownloadsSCCData/master/current_files/FCRCatwalk_L1.csv"
)


current_df <- qaqc_fcr(data_file = ds,
                    maintenance_file = 'https://raw.githubusercontent.com/FLARE-forecast/FCRE-data/refs/heads/fcre-catwalk-data-qaqc/FCR_CAT_MaintenanceLog.csv',
                    output_file = NULL,
                    start_date = ymd_hms("2018-07-05 14:45:00", tz="EST"),
                    end_date = Sys.Date() + lubridate::days(1),
                    dir = here::here())


# Remove dups that were introduced abbove.
  current_df <- current_df|>
  dplyr::distinct()%>% # get rid of dups if they snuck in
  filter(DateTime<(current_time_end))

# make sure no time duplicates.
 current_df<-  current_df[!duplicated(current_df$DateTime), ]

#reorder. Just to be certain everything is in order
  current_df<-current_df[order(current_df$DateTime),]


```

REVIEWERS- If you are reviewing this data package replace the pasta link with the one from EDI. If there are questions ask the data point person. There are two ways to use this script. You can either run it by chunks or you can knit it and make an html file. Knitting the file will run all the chunks and create an html page with all the plots. I like doing this because I can see all the plots in one place. The Knit button is on the top of the file with a ball of yarn and a needle next to it. 

```{r READ IN EDI FOR REVIEWER, eval = edi_stage, include = FALSE}

# # For REVIEWERS: Run this section to pull the data from EDI which is in staging as a check of the data.
# # MAKE SURE TO UPDATE THE PASTA FROM THE VERSION YOU WANT

                                                                ### CHANGE THIS NUMBER BELOW
 #                                                                             ##
 current_df <-read_csv(edi_link)

 # Force files from EDI to have an EST timestamp
  current_df$DateTime <- force_tz(as.POSIXct(current_df$DateTime), tzone = "EST")

```

```{r Download Raw data for plotting, include=FALSE}

# Get the raw files from the current year to compare with the QAQC file. I like having both on the same plot.

CATPRES_COL_NAMES = c("DateTime", "RECORD", "CR6Battery_V", "CR6Panel_Temp_C", "ThermistorTemp_C_surface",
                        "ThermistorTemp_C_1", "ThermistorTemp_C_2", "ThermistorTemp_C_3", "ThermistorTemp_C_4",
                        "ThermistorTemp_C_5", "ThermistorTemp_C_6", "ThermistorTemp_C_7", "ThermistorTemp_C_8",
                        "ThermistorTemp_C_9", "RDO_mgL_5", "RDOsat_percent_5", "RDOTemp_C_5", "RDO_mgL_9",
                        "RDOsat_percent_9", "RDOTemp_C_9", "EXO_Date", "EXO_Time", "EXOTemp_C_1", "EXOCond_uScm_1",
                        "EXOSpCond_uScm_1", "EXOTDS_mgL_1", "EXODOsat_percent_1", "EXODO_mgL_1", "EXOChla_RFU_1",
                        "EXOChla_ugL_1", "EXOBGAPC_RFU_1", "EXOBGAPC_ugL_1", "EXOfDOM_RFU_1", "EXOfDOM_QSU_1","EXOTurbidity_FNU_1",
                        "EXOPressure_psi", "EXODepth_m", "EXOBattery_V", "EXOCablepower_V", "EXOWiper_V","LvlPressure_psi_9", "LvlTemp_C_9")
  
 
  # read catwalk data and maintenance log
  # NOTE: date-times throughout this script are processed as UTC
  raw <- read_csv("https://raw.githubusercontent.com/FLARE-forecast/FCRE-data/fcre-catwalk-data/fcre-waterquality.csv", skip = 1, col_names = CATPRES_COL_NAMES,
                      col_types = cols(.default = col_double(), DateTime = col_datetime()))
  
  # Take out EXO_Date and EXO_Time
  raw <- raw%>%select(-c("EXO_Date", "EXO_Time"))
  
  #create depth column
  raw <- raw%>%mutate(LvlDepth_m_9=LvlPressure_psi_9*0.70455)#1psi=2.31ft, 1ft=0.305m
  
  
  # convert NaN to NAs in the dataframe
  raw[sapply(raw, is.nan)] <- NA
  
   # Force historical file timestamp to EST
  raw$DateTime <- force_tz(as.POSIXct(raw$DateTime), tzone = "EST")
  
  current <- raw%>%
  filter(DateTime>=current_time_start & DateTime<current_time_end)%>%
  mutate(type = "raw")

```

## Check for duplicates and  gaps in the data frame

This section identifies if there are any duplicates, daily data, and sub daily gaps in the long-term record. If there are duplicates, look to see if they are true duplicates and then check the qaqc function and the chunk above where duplicates should be removed. If there is nothing printed then there are no duplicates or missing files. 


### Are there any duplicates?

Check to see there are no duplicates in the data file. If there are then they need to be removed. 


```{r Check for dups , echo=FALSE}

# Make sure there are no duplicated dates. Do this here because the file is too large for Data Explore.
# Print them if there are
 dups<- current_df[duplicated(current_df$DateTime), ]

dups <- dups%>%
  select(DateTime, RECORD, ThermistorTemp_C_7,  RDO_mgL_5,
         EXOTemp_C_1, LvlPressure_psi_9) 

# Make it into a nice table when the Markdown is knitted together
knitr::kable((dups))
```


### Are there any gaps in the data file?


When gaps are found in the data file, check that you do not have new gaps in the previous years' publication. For the current year, if you find gaps check that you have all of the manually downloaded files. If the data are truly missing then record the dates and times in the methods section. 

```{r Check for daily gaps, echo=FALSE}

# Get DOY
bvrdata <- current_df
 bvrdata$DOY=yday(bvrdata$DateTime)

 for(i in 2:nrow(bvrdata)){ #this identifies if there are any data gaps in the long-term record, and where they are by record number
    if(bvrdata$DOY[i]-bvrdata$DOY[i-1]>1){
      print(c(bvrdata$DateTime[i-1],bvrdata$DateTime[i]))
    }
 }
```

### Are there any subdaily gaps?

This identifies if there are any sub-daily gaps in the current record which gets recorded in the methods section. 

The first row is the time for the first observation and then the subsequent observation. Each observation should be 10 minutes apart. The second row is the number of the record for each observation. Most of these gaps happen when we change the program on the data logger. These times will be recorded in the maintenance section of the metadata.

```{r Check for sub daily gaps, echo=FALSE}

# Because we can't have NAs for this for loop let's make a new df
 bvr2 <- current_df%>%
  filter(!is.na(RECORD)) %>%
  filter(DateTime>current_time_start)

  for(i in 2:length(bvr2$RECORD)){ #this identifies if there are any data gaps in the long-term record, and where they are by record number
    if( abs(bvr2$RECORD[i]-bvr2$RECORD[i-1])>1 & difftime(bvr2$DateTime[i], bvr2$DateTime[i-1], units="mins")>10){
      print(c(bvr2$DateTime[i-1], bvr2$DateTime[i]))
      print(c(bvr2$RECORD[i-1], bvr2$RECORD[i]))
    }
  }

print("If there are no observations here that means there are no gaps in the data for the current year.")
```


### Flag Frequency
Let's look at the flag Frequency for each variable. As a reminder here are the flag codes
 Flag values
 
 0: no flag
 
 1: value removed due to maintenance and set to NA
 
 2: negative or outlier value removed and set to NA, see Methods section for more detail on QAQC process
 
 3: negative values set to 0 except for temperature
 
 4: value removed due to fouling and set to NA
 
 5: questionable value but left in the dataset
 
 6: Values adjusted using a linear or square root function to match high-resolution CTD profiles and corrected other affected observations on the same sensor
 
 7: missing data
 
```{r Check out the flags, echo=FALSE}

#make sure no NAS in the Flag columns
Flags <- current_df%>%
  select(DateTime, starts_with("Flag"))

RowsNA=Flags[!complete.cases(Flags), ] # Keep only the complete rows

#check the flag column
Flags <- current_df%>%
  select(starts_with("Flag"))

# Make a table with the number of times a flag was used
for(f in 1:ncol(Flags)){
  print(colnames(Flags[f]))
  print(table(Flags[,f], useNA = "always"))
}
```


### Check to make sure that what is in the maintenance log was actually removed

### Look at the last row of the maintenance log 

We want to make sure that our maintenance log actually worked and took out the values or changes those it was supposed to 

```{r Read in the maintenance log and look at the tail, echo=FALSE}

# The streaming sensors use semicolons as a deliminator because of the adjustment_code column. We use the read_csv2 to read in the file. 
 maint <- read_csv2("https://raw.githubusercontent.com/FLARE-forecast/FCRE-data/fcre-catwalk-data-qaqc/FCR_CAT_MaintenanceLog.csv",
                    show_col_types = FALSE)


# name the data file for just the tail of the maintenance log
# you want to filter out 7 because that is if the observation is missing and there are other ways that is flagged in the data besides the maintenance log, so it is not a good check.
sd <- tail(maint)%>%
  filter(flag!=7)


knitr::kable((tail(sd, n= 1)))

```
#### Check the that the columns have flags 

Look at the first few rows of the data frame and check that the observations after the TIMESTAMP_start are flagged

#### Look at the first 2 rows for that time

```{r Did the maint log work head, echo=FALSE, message=FALSE, warning=FALSE}
# get the last row of the data file
last_row <- tail(sd, n=1)

# Get starttime and end time
### get start and end time of one maintenance event
    start <- force_tz(as.POSIXct(last_row$TIMESTAMP_start), tzone = "EST")
    end <- force_tz(as.POSIXct(last_row$TIMESTAMP_end), tzone = "EST")
    
    # Get the time of the maintenance
    if(is.na(end)){
      # If there the maintenance is on going then the columns will be removed until
      # and end date is added
      Time <- current_df |> filter(DateTime >= start) |> select(DateTime)
      
    }else if (is.na(start)){
      # If there is only an end date change columns from beginning of data frame until end date
      Time <- current_df |> filter(DateTime <= end) |> select(DateTime)
      
    }else {
      Time <- current_df |> filter(DateTime >= start & DateTime <= end) |> select(DateTime)
    }


### Get the names of the columns affected by maintenance
    colname_start <- last_row$start_parameter
    colname_end <- last_row$end_parameter
    
    # Make list of just the columns we want 
    
    test <- colnames(current_df%>%select(DateTime, colname_start, paste0("Flag_",colname_start), colname_end, paste0("Flag_",colname_end)))
    
    # Print the head of the table to make sure that data are flagged
    
    knitr::kable((head(current_df[current_df$DateTime %in% Time$DateTime, test], n =2))) 

```

#### Look at the last 2 rows for the maintenance time

Make sure the observations are flagged

```{r Print the tails, echo=FALSE, message=FALSE, warning=FALSE}

# Print the tail of the table to make sure that data are flagged
    
    knitr::kable(tail(current_df[current_df$DateTime %in% Time$DateTime, test], n=2)) 

```


## QAQC Plots

##### QAQC plot information and all_plot function information

For the plots, they use a function called "all_plot". In all_plot you can specify if you want interactive plots for the current data. You can specify which plotly plots you want on. You can also look at the plotly plots manually in each chunk by running the chunk with Use_plotly=TRUE as an argument. Then look at the list of plots you have made under "output". If you click on the "output" object in your environment it will list all of the plots and which ones are interactive plotly plots. To view the plots run "output[[number of the plot in the list you want to run]]". Eg. If you want to see the 4th plot in the list write output[[4]] then run that line and the plot should appear. 

If you would like to look at one variable then in the function below replace "dx" with the variable column. The object "dx" is just a list of variables so we don't have to list out all of the variables we want to plot. This is used to speed up the process. 

The plotting function is called all_plot() which plots the 4 or more plots described below. The function is sourced from GitHub in the first chunk of the script. The arguments are:
Var, # the variable you would like to plot
data, # the data frame to use
raw_data=NULL, # Is there raw data to compare with. Usually is NULL
reservoir, # the name of the reservoir you would like to filter by 
res_site, # the reservoir Site or Sites you would like to filter by
y_lab,  # This label can take an expression aka have the proper degrees C, 
y_lab2, # This label is for the plotly function which can not handle expression argument. 
Depth=F,  # Do you want depth as a factor
Water=T, # Are these plots for streaming sensors with RDO and temperature sensors
Use_plotly = F, # Do you want to produce interactive plots for observations of the current year?
Heatmap = F) # Do you want to make a heat maps? This only works if there are multiple depths at the same site


The arguments with = followed by a True means that they are the defaults and you don't need to add them to the function when you use it. If you want to use the opposite of the default you must specify that. 
  
##### Plot Description:

The plots below are:
The first 2 plots are the ones you should focus on for the QAQC check. Spend the most time looking at the most recent data because that one as been checked. Do pay attention to the historical to make sure there are no crazy outliers that were missed in previous years. 

1. A time series of the current years' data. This can either be a regular plot or an interactive one. If you would like it to be interactive set Use_plotly = T. The black dots are the qaqced observations and the red is the raw files that were qaqced. This is to see what kind of values were removed and if there are any the script missed or that need to be added to the maintenance log. 

2. A time series of the historical and the current data just the qaqced values. 

The next two plots are just fun to see trends over time with the data. 

3. Density plots are like a histogram and a grouped by color so you can see where the data are relative to other years. 

4. The box plots look at the spread of the data within the year and we can look at the median and see how that is changing or not. 

Do not over think the last 2 plots, although they are good to look at historical trends to ensure relative data quality consistency. 

There are additional plots for depths that have more than one sensor such as at position 13 that has a thermistor and a pressure transducer which both measure temperature. In this case, we plot them on top of each other to make sure they are within the ballpark. For chla and the bluegreen algae sensor on the EXO2 we plot the daily observations on top of the 10 minute observations to make sure that the daily captures the same trend as the 10 minute data. 


### Temperature

```{r Temp, echo=FALSE, results='asis'}

dx <- colnames(current%>%select(grep("Temp_C_[0-9A-Za-z]",colnames(current))))

# If you would like to see the plots for one data column. Replace "dx" with the variable name and run the function. 

# make the plots
outputs <- lapply(dx, all_plot, data= current_df, raw_data = raw, reservoir = "FCR", y_lab = expression(''*~degree*C*''), y_lab2 = "Degrees C", Use_plotly=F)

output <- unlist(outputs, recursive = F)

# If you are running this chunk by chunk uncomment the line to make the interactive plot. Note that "output" lists 16 different plots
#output[[1]]

```

```{r Print plotly temp, echo=FALSE, messages=FALSE, warning=FALSE}

 # Used to print the plotly plots
  # attach the Dependencies
  # since the do not get included with renderTags(...)$html
  deps <- lapply(
    Filter(function(x){inherits(x,"htmlwidget")},output),
    function(hw){
      renderTags(hw)$dependencies
    }
  )
  
  if(length(deps)>0){
  attachDependencies(
    tagList(),
    unlist(deps,recursive=FALSE)
  )
  }  
```


```{r All Temperature, echo=FALSE, warning=FALSE, results='hide'}

colors3 <-c("0.1m"="firebrick1", "1m"="DarkOrange1", "EXO_1.5m"="yellow","2m"="gold", 
                                  "3m"="greenyellow", "4m"="medium sea green", "5m"="sea green",
                                  "6m"="DeepSkyBlue4", "7m"="blue2", "8m"="darkslateblue", "9m"="darkmagenta")

# Take out Temperature values 

  All_temp<-current_df%>%
    select(DateTime, starts_with("Ther"), starts_with("EXOTemp"))%>%
    pivot_longer(-c(DateTime), names_to="Sensor", values_to="Reading", values_drop_na=TRUE)%>%
    mutate(DateTime=ymd_hms(DateTime))
  
  
  ggplot(All_temp)+
    geom_scattermore(aes(x=DateTime, y=Reading))+
    facet_wrap(.~factor(Sensor, levels=c("ThermistorTemp_C_surface","ThermistorTemp_C_1","EXOTemp_C_1", "ThermistorTemp_C_2",  "ThermistorTemp_C_3", "ThermistorTemp_C_4","ThermistorTemp_C_5","RDOTemp_C_5","ThermistorTemp_C_6","ThermistorTemp_C_7","ThermistorTemp_C_8","ThermistorTemp_C_9", "RDOTemp_C_9","LvlTemp_C_9")))+
    theme_bw()
  
  
# This is all the temps and just the current year
    ggplot(current,aes(x = DateTime))+
    geom_line(aes(y=ThermistorTemp_C_surface, color="0.1m"))+
    geom_line(aes(y=ThermistorTemp_C_1, color="1m"))+
    geom_line(aes(y=EXOTemp_C_1, color="EXO_1.5m")) +
    geom_line(aes(y=ThermistorTemp_C_2, color="2m"))+
    geom_line(aes(y=ThermistorTemp_C_3, color="3m"))+
    geom_line(aes(y=ThermistorTemp_C_4, color="4m"))+
    geom_line(aes(y=ThermistorTemp_C_5, color="5m"))+
    geom_line(aes(y=ThermistorTemp_C_6, color="6m"))+
    geom_line(aes(y=ThermistorTemp_C_7, color="7m"))+
    geom_line(aes(y=ThermistorTemp_C_8, color="8m"))+
    geom_line(aes(y=ThermistorTemp_C_9, color="9m"))+
    ggtitle("Current Temperature Profile") +
    labs(y = expression(''*~degree*C*''),
           color = "Legend") +
      scale_color_manual(values = colors3)+
      theme_bw()
  
```

### Depth

```{r Pressure Sensor, echo=FALSE, results='asis'}
### Plotting depth from pressure sensor 
   
dx <- colnames(current%>%select(grep("Depth_m",colnames(current))))

# If you would like to see the plots for one data column. Replace "dx" with the variable name and run the function. 

# make the plots
outputs <- lapply(dx, all_plot, data= current_df, raw_data = raw, reservoir = "FCR", y_lab = "Meters", y_lab2 = "Meters", Use_plotly=F)

output <- unlist(outputs, recursive = F)

# If you are running this chunk by chunk uncomment the line to make the interactive plot. Note that "output" lists 16 different plots
#output[[1]]

```

```{r Print plotly pres, echo=FALSE, messages=FALSE, warning=FALSE}

 # Used to print the plotly plots
  # attach the Dependencies
  # since the do not get included with renderTags(...)$html
  deps <- lapply(
    Filter(function(x){inherits(x,"htmlwidget")},output),
    function(hw){
      renderTags(hw)$dependencies
    }
  )
  if(length(deps)>0){
  attachDependencies(
    tagList(),
    unlist(deps,recursive=FALSE)
  )
  }  
```

### Dissolved Oxygen

```{r DO, echo=FALSE, results='asis'}


dx <- colnames(current%>%select(grep("DO_mgL|sat_percent",colnames(current))))

# If you would like to see the plots for one data column. Replace "dx" with the variable name and run the function. 

# make the plots
outputs <- lapply(dx, all_plot, data= current_df, raw_data = raw, reservoir = "FCR", y_lab = "mg/L or % sat", y_lab2 = "mg/L or % sat", Use_plotly=T)

output <- unlist(outputs, recursive = F)

# If you are running this chunk by chunk uncomment the line to make the interactive plot. Note that "output" lists 16 different plots
#output[[1]]
```

```{r Print plotly DO, echo=FALSE, messages=FALSE, warning=FALSE}

 # Used to print the plotly plots
  # attach the Dependencies
  # since the do not get included with renderTags(...)$html
  deps <- lapply(
    Filter(function(x){inherits(x,"htmlwidget")},output),
    function(hw){
      renderTags(hw)$dependencies
    }
  )
  
  if(length(deps)>0){
  attachDependencies(
    tagList(),
    unlist(deps,recursive=FALSE)
  )
  }  
```

### Chlorophyll and Phycocanin

```{r Check the EXO Chla and Blue Greens, echo=FALSE, results='asis'}

dx <- colnames(current%>%select(grep("Chla|BGAPC",colnames(current))))

# If you would like to see the plots for one data column. Replace "dx" with the variable name and run the function. 

# make the plots
outputs <- lapply(dx, all_plot, data= current_df, raw_data = raw, reservoir = "FCR", y_lab = "RFU or ug/L", y_lab2 = "RFU or ug/L", Use_plotly = T)

output <- unlist(outputs, recursive = F)

# If you are running this chunk by chunk uncomment the line to make the interactive plot. Note that "output" lists 16 different plots
#output[[1]]
```

```{r Print plotly algae, echo=FALSE, warning=FALSE, messages=FALSE}


 # Used to print the plotly plots
  # attach the Dependencies
  # since the do not get included with renderTags(...)$html
  deps <- lapply(
    Filter(function(x){inherits(x,"htmlwidget")},output),
    function(hw){
      renderTags(hw)$dependencies
    }
  )
  if(length(deps)>0){
  attachDependencies(
    tagList(),
    unlist(deps,recursive=FALSE)
  )
  }  
```

### fDOM

```{r fdom EXO sensor, echo=FALSE, results='asis'}

dx <- colnames(current%>%select(grep("fDOM",colnames(current))))

# If you would like to see the plots for one data column. Replace "dx" with the variable name and run the function. 

# make the plots
outputs <- lapply(dx, all_plot, data= current_df, raw_data = raw, reservoir = "FCR", y_lab = "RFU or QSU", y_lab2 = "RFU or QSU", Use_plotly=T)

output <- unlist(outputs, recursive = F)

# If you are running this chunk by chunk uncomment the line to make the interactive plot. Note that "output" lists 16 different plots
#output[[1]]
```

```{r Print plotly fdom, echo=FALSE, messages=FALSE, warning=FALSE}

 # Used to print the plotly plots
  # attach the Dependencies
  # since the do not get included with renderTags(...)$html
  deps <- lapply(
    Filter(function(x){inherits(x,"htmlwidget")},output),
    function(hw){
      renderTags(hw)$dependencies
    }
  )
  
  if(length(deps)>0){
  attachDependencies(
    tagList(),
    unlist(deps,recursive=FALSE)
  )
  }  
```

### Conductivity, Specific Conductivity, TDS

```{r Cond Spcond and TDS, echo=FALSE, results='asis'}

dx <- colnames(current%>%select(grep("^EXOSpCond|^EXOCond|^EXOTDS",colnames(current))))

# If you would like to see the plots for one data column. Replace "dx" with the variable name and run the function. 

# make the plots
outputs <- lapply(dx, all_plot, data= current_df, raw_data = raw, reservoir = "FCR", y_lab = "uScm or mg/L", y_lab2 = "uScm or mg/L", Use_plotly=F)

output <- unlist(outputs, recursive = F)

# If you are running this chunk by chunk uncomment the line to make the interactive plot. Note that "output" lists 16 different plots
#output[[1]]
```

```{r Print plotly cond, echo=FALSE, messages=FALSE, warning=FALSE}

 # Used to print the plotly plots
  # attach the Dependencies
  # since the do not get included with renderTags(...)$html
  deps <- lapply(
    Filter(function(x){inherits(x,"htmlwidget")},output),
    function(hw){
      renderTags(hw)$dependencies
    }
  )
  
  if(length(deps)>0){
  attachDependencies(
    tagList(),
    unlist(deps,recursive=FALSE)
  )
  }  
```

### Turbidity

```{r turbidity, echo=FALSE, results='asis'}

# If you would like to see the plots for one data column. Replace "dx" with the variable name and run the function. 

# make the plots
outputs <- lapply("EXOTurbidity_FNU_1", all_plot, data= current_df, raw_data = raw, reservoir = "FCR", y_lab="FNU", y_lab2="FNU")

output <- unlist(outputs, recursive = F)

# If you are running this chunk by chunk uncomment the line to make the interactive plot. Note that "output" lists 16 different plots
#output[[1]]
```

```{r Print plotly tur, echo=FALSE, messages=FALSE, warning=FALSE}

 # Used to print the plotly plots
  # attach the Dependencies
  # since the do not get included with renderTags(...)$html
  deps <- lapply(
    Filter(function(x){inherits(x,"htmlwidget")},output),
    function(hw){
      renderTags(hw)$dependencies
    }
  )
  
  if(length(deps)>0){
  attachDependencies(
    tagList(),
    unlist(deps,recursive=FALSE)
  )
  }  
```

### Wiper, Battery, and CablePower

```{r Wiper, echo=FALSE, results='asis'}

dx <- colnames(current%>%select(grep("Wiper_V|Battery_V|power_V",colnames(current))))

# If you would like to see the plots for one data column. Replace "dx" with the variable name and run the function. 

# make the plots
outputs <- lapply(dx, all_plot, data= current_df, raw_data = raw, reservoir = "FCR", y_lab="Volts", y_lab2="Volts")

output <- unlist(outputs, recursive = F)

# If you are running this chunk by chunk uncomment the line to make the interactive plot. Note that "output" lists 16 different plots
#output[[1]]
```

```{r Print plotly power, echo=FALSE, messages=FALSE, warning=FALSE}

 # Used to print the plotly plots
  # attach the Dependencies
  # since the do not get included with renderTags(...)$html
  deps <- lapply(
    Filter(function(x){inherits(x,"htmlwidget")},output),
    function(hw){
      renderTags(hw)$dependencies
    }
  )
  
  if(length(deps)>0){
  attachDependencies(
    tagList(),
    unlist(deps,recursive=FALSE)
  )
  }  
```

### Write to CSV
Make the data frame here and it will save where your inspection script is saved. 

```{r Make current csv, eval = make_data, include=FALSE}
# Double Check naming convention
# Variable_StartYear_EndYear

# convert datetimes to characters so that they are properly formatted in the output file
 current_df$DateTime <- as.character(format(current_df$DateTime))

write_csv(current_df, file_name)

```

### Download and save Maintenance Log, Plotting function, and QAQC function

```{r Download and save Maintenance Log, eval = make_data, inclue = FALSE}

# Download the most recent maintenance log, qaqc file, and plotting function from GitHub. 

# Maintenance Log
download.file("https://raw.githubusercontent.com/FLARE-forecast/FCRE-data/fcre-catwalk-data-qaqc/FCR_CAT_MaintenanceLog.csv", maintenance_log)

# qaqc function
download.file("https://raw.githubusercontent.com/FLARE-forecast/FCRE-data/fcre-catwalk-data-qaqc/R/edi_qaqc_function.R", qaqc_function)

# streaming plots function
download.file("https://raw.githubusercontent.com/CareyLabVT/Reservoirs/master/Data/DataAlreadyUploadedToEDI/EDIProductionFiles/Plotting_function.R", "Plotting_function.R")


```

