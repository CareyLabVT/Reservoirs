---
title: "isco_inspection_2019_2024"
author: "Carly Bauer - edited from ABP"
date: "2023=5-05-07"
output: html_document
---

This is a template to make your visual inspection script. It does not have to be an R Markdown but I like then especially the knit function so I can send the plots to coauthors. Make sure all of the columns get plotted even ones you think might not be that relevant. 

## R Markdown Guide

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document.

```{r setup packages, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

# Add the names of the packages 
pacman::p_load(tidyverse, lubridate, gsheet, ggplot2, dplyr)
```



```{r Read in Historical files from EDI}
# 
# inUrl1  <- ADD PASTA FROM EDI HERE
# infile1 <- tempfile()
# try(download.file(inUrl1,infile1,method="curl"))
# if (is.na(file.size(infile1))) download.file(inUrl1,infile1,method="auto")
# 
#                    
#  historic <-read_csv(infile1)

```


```{r Read in L1 file}

# L1 <- read_csv(LINK TO L1 FILE HERE)

```

```{r Bind historic and L1 files together}

# current_df <- dplyr::bind_rows(historic, L1)

```


```{r Load csv}

current_df <- read_csv("https://raw.githubusercontent.com/carlybauer/Reservoirs/refs/heads/master/Data/DataAlreadyUploadedToEDI/EDIProductionFiles/MakeEML_ISCO/2025/isco_2019_2024.csv")

```

This section checks to make sure each observation has a data flag. It also checks to make sure the frequency of flags match what we expect to see. 

```{r Check there are no NAs in Flag columns}

#make sure no NAS in the Flag columns
Flags=current_df%>%
  select(Collection_start_time, starts_with("Flag"))

RowsNA=Flags[!complete.cases(Flags), ] # Keep only the complete rows

#check the flag column
Flags=current_df%>%
  select(starts_with("Flag"))

# Make a table with the number of times a flag was used
for(f in 1:(ncol(Flags))){
  #print(colnames(Flags[f]))
  print(table(Flags[,f], useNA = "always"))
}

```

### Check to make sure that what is in the maintenance log was actually removed

### Look at the last rows of the maintenance log 

We want to make sure that our maintenance log actually worked and took out the values or changes those it was supposed to 

```{r Read in the maintenance log and look at the tail, echo=FALSE}

# The streaming sensors use semicolons as a deliminator because of the adjustment_code column. We use the read_csv2 to read in the file. 
 maint <- read_csv("https://raw.githubusercontent.com/CareyLabVT/Reservoirs/master/Data/DataNotYetUploadedToEDI/Metals_Data/Metals_Maintenance_Log.csv",
                    show_col_types = FALSE)|>
  filter(Site == 100.1)


# name the data file for just the tail of the maintenance log

sd <- tail(maint)


knitr::kable((tail(sd)))

```

#### Check the that the columns have flags 

Look at the first few rows of the data frame and check that the observations after are flagged.
Some of the flags are added to in the script so the value was flagged with 6 in the maintenance log 
but in the script it was added to because the value was lower than the Minimum reporting level. 
Just make sure that one of the values is in the mainteance log.

#### Look at the first row in the maintenance time. Is the correct observation flagged?

Make sure the observations are flagged

```{r Print the tails, echo=FALSE}

# Print the tail of the table to make sure that data are flagged

last_row <- head(sd, n=1)

# Get parameters for subsetting
### get start and end time of one maintenance event
    start <- as.Date(last_row$Sample_Date)
    
    # Reservoir 
    Res <- last_row$Reservoir
    
    # Site 
    Sit <- as.numeric(last_row$Site)
    
    # Depth
    Dep <- as.numeric(last_row$Depth_m)
    
    # Filter
    Filt <- last_row$Filter


### Get the names of the columns affected by maintenance
    colname_start <- last_row$start_parameter
    colname_end <- last_row$end_parameter
    
     # What we want to filter from 
    
    check <- (as.Date(current_df$DateTime) %in% start & 
            current_df$Reservoir %in% Res & 
              current_df$Site %in% Sit &
              current_df$Depth_m %in% Dep) 
    
    # Make list of just the columns we want 
    
    test <- colnames(current_df%>%select(Reservoir,Site, DateTime, Depth_m,paste0(Filt, colname_start), paste0("Flag_",Filt,colname_start), paste0(Filt,colname_end), paste0("Flag_", Filt,colname_end)))
    
    

# Print the head of the table to make sure that data are flagged
    
    knitr::kable((head(current_df[check, test])))

```

#### Look at the last row of the maintenance log. Are the columns flagged?

```{r Did the maint log work head, echo=FALSE}
# get the last row of the data file
last_row <- tail(sd, n=1)

# Get parameters for subsetting
### get start and end time of one maintenance event
    start <- as.Date(last_row$Sample_Date)
    
    # Reservoir 
    Res <- last_row$Reservoir
    
    # Site 
    Sit <- as.numeric(last_row$Site)
    
    # Depth
    Dep <- as.numeric(last_row$Depth_m)
    
    # Filter
    Filt <- last_row$Filter


### Get the names of the columns affected by maintenance
    colname_start <- last_row$start_parameter
    colname_end <- last_row$end_parameter
    
    
    # What we want to filter from 
    
    check <- (as.Date(current_df$DateTime) %in% start & 
            current_df$Reservoir %in% Res & 
              current_df$Site %in% Sit &
              current_df$Depth_m %in% Dep) 
    
    # Make list of just the columns we want 
    
    test <- colnames(current_df%>%select(Reservoir,Site, DateTime, Depth_m,paste0(Filt, colname_start), paste0("Flag_",Filt,colname_start), paste0(Filt,colname_end), paste0("Flag_", Filt,colname_end)))
    
    # Print the head of the table to make sure that data are flagged
    
    knitr::kable((head(current_df[check, test]))) 

```


## QAQC Plots

```{r Plots load_kg}
# Filter data with valid loads
plot_df <- current_df %>%
  mutate(Year = lubridate::year(Collection_start_time))

# Get list of unique elements
elements <- unique(plot_df$Element_name)

# Loop over each element and plot
for (el in elements) {
  p <- plot_df %>%
    filter(Element_name == el) %>%
    ggplot(aes(x = Collection_start_time, y = Load_kg)) +
    geom_point() +
    facet_wrap(~ Year, scales = "free_x") +  # allow each year to have its own x-axis
    labs(
      title = paste("Load Over Time for", el),
      x = "Date",
      y = "Load (kg)"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      strip.text = element_text(face = "bold")
    )
  
  print(p)
}


```
```{r Plots load_kgD}
# Filter data with valid loads
plot_df <- current_df %>%
  mutate(Year = lubridate::year(Collection_start_time))

# Get list of unique elements
elements <- unique(plot_df$Element_name)

# Loop over each element and plot
for (el in elements) {
  p <- plot_df %>%
    filter(Element_name == el) %>%
    ggplot(aes(x = Collection_start_time, y = Load_kgD)) +
    geom_point() +
    facet_wrap(~ Year, scales = "free_x") +  # allow each year to have its own x-axis
    labs(
      title = paste("Load Over Time for", el),
      x = "Date",
      y = "Load (kg/day)"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      strip.text = element_text(face = "bold")
    )
  
  print(p)
}


```

```{r Plot loads with discharge}
#load discharge data 
discharge <- read_csv("https://pasta.lternet.edu/package/data/eml/edi/202/12/aae7888d68753b276d1623680f81d5de")

# separate DateTime column so you can grab just year of interest
discharge <- mutate(discharge, 
                    DateTime = ymd_hms(DateTime),
                    Year = year(DateTime),
                    Date = date(DateTime),
                    Hour = hour(DateTime))

# filter to just look at years we have sed trap data for
discharge <- discharge %>% 
  filter(Year>=2019)


# mean flow for every hour: first groups by the date
# so we get mean flow for everyday of 2020s and every hour of that day
discharge_mean <- discharge %>% 
  group_by(Date) %>% 
  summarise(mean_WVWA_cms = mean(coalesce(WVWA_Flow_cms, VT_Flow_cms), na.rm = TRUE)) %>% 
  mutate(Year = year(Date)) %>% 
  ungroup() 

# Load data prep
load_df <- current_df %>%
  mutate(Date = as.Date(Collection_start_time)) %>%
  select(Date, Element_name, Load_kg)

# Restrict discharge to overlap with load data 
## This isn't working 
discharge_trimmed <- discharge_mean %>%
  filter(Date >= min(load_df$Date),
         Date <= max(load_df$Date))

# List of elements to plot
elements <- unique(load_df$Element_name)

# Loop to plot
for (el in elements) {
  
  # Filter load data for element
  df_el <- load_df %>% filter(Element_name == el)
  
  # Merge discharge with load (for shared x-axis)
  plot_data <- discharge_trimmed %>%
    left_join(df_el, by = "Date")
  
  # Scale factor for dual axis (adjust as needed)
  scaleFactor <- max(plot_data$Load_kg, na.rm = TRUE) / max(plot_data$mean_WVWA_cms, na.rm = TRUE)
  
  # Plot
  p <- ggplot(plot_data, aes(x = Date)) +
        geom_point(aes(y = mean_WVWA_cms * scaleFactor), color = "blue", alpha = 0.7) +
    geom_point(aes(y = Load_kg), color = "red", size = 1, na.rm = TRUE) +
    scale_y_continuous(
      name = "Load (kg)",
      sec.axis = sec_axis(~ . / scaleFactor, name = "Discharge (cms)")
    ) +
    labs(
      title = paste("Load and Discharge Over Time:", el),
      x = "Date") +
        facet_wrap(~ Year, scales = "free_x") +  # facet by year
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      legend.position = "none"
    )
  
  print(p)
}


```


```{r Make new CSV with current and historic files, eval=FALSE, include=FALSE}

# Convert DateTime to a character
# convert datetimes to characters so that they are properly formatted in the output file
 current_df$DateTime <- as.character(format(current_df$DateTime))

# Need to decide on a naming convention for this file
write_csv(current_df, "isco_2019_2024.csv")

```



```{r Download and save Maintenance Log, eval=FALSE, include=FALSE}

# This chunkt to download files needs to be run by itself. Just click on the green arrow to download the files. 

# Maintenance Log
download.file("https://raw.githubusercontent.com/CareyLabVT/Reservoirs/master/Data/DataNotYetUploadedToEDI/Metals_Data/Metals_Maintenance_Log.csv", "metals_maintenancelog_2014_2024.csv")

## Maybe we want to take out the ISCO observations in the maintenance log
 maint <- read_csv("https://raw.githubusercontent.com/CareyLabVT/Reservoirs/master/Data/DataNotYetUploadedToEDI/Metals_Data/Metals_Maintenance_Log.csv",
                    show_col_types = FALSE)|>
  filter(Site == 100.1)
 
 # save the csv without ISCO samples in maint log
 
 write.csv(maint, "isco_maintenancelog_2019_2024.csv")

# qaqc function
# update link when change the location of the script
download.file("https://raw.githubusercontent.com/CareyLabVT/Reservoirs/master/Scripts/L1_functions/metals_create.R", "isco_qaqc_2014_2024.R")


# Anything else that needs to be added? MDL file?


```

### Make a site description file

```{r Make site description file, eval=FALSE, include=FALSE}
 # These lines of code make the csv of the site descriptions with lat and long. To generate the site description file, click the green arrow on the right. 

  # Use Gsheet because you don't need to authenticate it. 
  sites <- gsheet::gsheet2tbl("https://docs.google.com/spreadsheets/d/1TlQRdjmi_lzwFfQ6Ovv1CAozmCEkHumDmbg_L4A2e-8/edit#gid=1244423834")
  #data<- read_csv("YOUR DATA.csv")# Use this if you read in a csv
  data <- current_df #This is the line you need to modify!
  trim_sites = function(data,sites){
    data_res_site=data%>% #Create a Reservoir/Site combo column
      mutate(res_site = trimws(paste0(Reservoir,Site)))
    sites_merged = sites%>% #Filter to Sites that are in the dataframe
      mutate(res_site = trimws(paste0(Reservoir,Site)))%>%
      filter(res_site%in%data_res_site$res_site)%>%
      select(-res_site)
  }
  sites_trimmed = trim_sites(data,sites) 
  write.csv(sites_trimmed,"site_descriptions.csv", row.names=F)# Write to file

```

